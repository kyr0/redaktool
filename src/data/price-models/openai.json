{
  "openai-o1-mini": {
    "provider": "openai",
    "input": 0.000005,
    "output": 0.000015,
    "maxContextTokens": 128000,
    "maxInputTokens": 123904,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "o1-mini"
  },
  "openai-o1-preview": {
    "provider": "openai",
    "input": 0.000005,
    "output": 0.000015,
    "maxContextTokens": 128000,
    "maxInputTokens": 123904,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "o1-preview"
  },
  "openai-gpt-4o": {
    "provider": "openai",
    "input": 0.000005,
    "output": 0.000015,
    "maxContextTokens": 128000,
    "maxInputTokens": 123904,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "gpt-4o"
  },
  "openai-gpt-4o-mini": {
    "provider": "openai",
    "input": 0.000005,
    "output": 0.000015,
    "maxContextTokens": 128000,
    "maxInputTokens": 123904,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "gpt-4o"
  },
  "openai-gpt-4-turbo": {
    "provider": "openai",
    "input": 0.00001,
    "output": 0.00003,
    "maxContextTokens": 128000,
    "maxInputTokens": 123904,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "gpt-4-turbo"
  },
  "openai-gpt-3.5-turbo": {
    "provider": "openai",
    "input": 0.0000005,
    "output": 0.0000015,
    "maxContextTokens": 16384,
    "maxInputTokens": 12288,
    "maxOutputTokens": 4096,
    "tikTokenModelName": "gpt-3.5-turbo"
  }
}
